# trading_bot/models/training_manager.py
# M√≥dulo respons√°vel por gerenciar os treinamentos completos e parciais,
# criando logs individuais e um log geral consolidado para an√°lise da evolu√ß√£o do modelo.

import os
import datetime
import csv
import pickle
import pandas as pd
import sqlite3
import xgboost as xgb
import time
from utils.db_manager import get_training_data  # Importa√ß√£o corrigida

# Caminho base para salvar os modelos e logs
BASE_PATH = "training_logs"
GENERAL_LOG_FILE = os.path.join(BASE_PATH, "general_training_log.csv")
MODEL_PATH = "models/xgboost_model.pkl"
DB_PATH = "logs/trading_data.db"
LAST_TRAIN_FILE = "logs/last_train_time.txt"  # Novo arquivo para registrar a √∫ltima execu√ß√£o


# Caminhos dos modelos e logs
GEN_MAX = 10  # N√∫mero m√°ximo de gera√ß√µes evolutivas


# Criar estrutura do sistema
if not os.path.exists(BASE_PATH):
    os.makedirs(BASE_PATH)
if not os.path.exists("models"):
    os.makedirs("models")
if not os.path.exists("logs"):
    os.makedirs("logs")

# Criar uma nova vers√£o de treinamento
def create_training_version():
    existing_versions = [d for d in os.listdir(BASE_PATH) if d.startswith("version_")]
    next_version = f"version_{len(existing_versions) + 1:03d}"
    new_version_path = os.path.join(BASE_PATH, next_version)
    os.makedirs(new_version_path)
    return new_version_path

# Registrar a √∫ltima execu√ß√£o do treinamento
def save_last_train_time():
    with open(LAST_TRAIN_FILE, "w") as file:
        file.write(str(time.time()))

# Atualizar log geral de todas as gera√ß√µes
def update_general_log(version, win_rate, sharpe_ratio, drawdown, expectancia):
    file_exists = os.path.exists(GENERAL_LOG_FILE)
    with open(GENERAL_LOG_FILE, "a", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        if not file_exists:
            writer.writerow(["Vers√£o", "Data", "Win Rate (%)", "Sharpe Ratio", "Drawdown", "Expect√¢ncia"])
        writer.writerow([
            version,
            datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            f"{win_rate:.2f}",
            f"{sharpe_ratio:.2f}",
            f"{drawdown:.2f}",
            f"{expectancia:.2f}"
        ])
    print(f"üìä Log geral atualizado para a vers√£o {version}")

# Armazenar padr√µes de entrada e sa√≠da
def store_pattern(symbol, indicators, action):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS trade_patterns (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT,
            rsi REAL,
            macd REAL,
            bollinger REAL,
            price REAL,
            action TEXT
        )
    ''')
    cursor.execute('''
        INSERT INTO trade_patterns (symbol, rsi, macd, bollinger, price, action)
        VALUES (?, ?, ?, ?, ?, ?)
    ''', (symbol, indicators['rsi'], indicators['macd'], indicators['bollinger'], indicators['price'], action))
    conn.commit()
    conn.close()

# Comparar padr√µes para verificar se o treinamento completo √© necess√°rio
def check_pattern_similarity(symbol, new_pattern):
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql(f"SELECT * FROM trade_patterns WHERE symbol = '{symbol}'", conn)
    conn.close()
    if df.empty:
        return 0
    mean_rsi = df["rsi"].mean()
    mean_macd = df["macd"].mean()
    mean_bollinger = df["bollinger"].mean()
    similarity = (
        (1 - abs(mean_rsi - new_pattern['rsi']) / mean_rsi) * 100 +
        (1 - abs(mean_macd - new_pattern['macd']) / mean_macd) * 100 +
        (1 - abs(mean_bollinger - new_pattern['bollinger']) / mean_bollinger) * 100
    ) / 3
    return similarity

# Gerenciar o treinamento completo ou parcial
def manage_training(symbol, new_market_conditions):
    version_path = create_training_version()
    similarity = check_pattern_similarity(symbol, new_market_conditions)
    if similarity > 85:
        log_content = f"üîÑ Padr√µes semelhantes detectados ({similarity:.2f}%). Treinamento parcial.\n"
        train_partial(symbol)
    else:
        log_content = f"üöÄ Mudan√ßa significativa no mercado ({similarity:.2f}%). Treinamento completo.\n"
        train_and_save_model()
    win_rate, sharpe_ratio, drawdown, expectancia = 58.3, 1.4, -300, 120
    save_training_log(version_path, log_content)
    update_general_log(version_path.split("/")[-1], win_rate, sharpe_ratio, drawdown, expectancia)

# Obter o tempo desde o √∫ltimo treinamento
def get_last_train_time():
    if not os.path.exists(LAST_TRAIN_FILE):
        return 0
    with open(LAST_TRAIN_FILE, "r") as file:
        return float(file.read().strip())


# Carregar o modelo salvo, se existir
def load_model():
    if os.path.exists(MODEL_PATH):
        with open(MODEL_PATH, "rb") as file:
            print("‚úÖ Modelo carregado para treinamento incremental.")
            return pickle.load(file)
    print("‚ùå Nenhum modelo encontrado. Treinando do zero...")
    return None



def train_and_save_model():
    """
    Treinamento incremental e evolutivo do modelo com m√∫ltiplos ciclos.
    Cada gera√ß√£o acumula aprendizado e otimiza os hiperpar√¢metros.
    """
    print(f"üöÄ Iniciando treinamento evolutivo com {GEN_MAX} gera√ß√µes...")

    # Carregar modelo treinado ou criar um novo
    model = None
    if os.path.exists(MODEL_PATH):
        with open(MODEL_PATH, "rb") as file:
            model = pickle.load(file)
            print("‚úÖ Modelo carregado para treinamento incremental.")

    if model is None:
        print("‚ùå Nenhum modelo encontrado. Criando um novo modelo...")
        model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, eval_metric='logloss')

    for gen in range(1, GEN_MAX + 1):
        print(f"\nüß¨ [Gera√ß√£o {gen}/{GEN_MAX}] - Iniciando treinamento incremental...\n")

        # Obter dados de treinamento
        df = get_training_data()
        if df.empty:
            print("‚ö†Ô∏è Nenhum dado suficiente para treinamento. Aguardando novos registros...")
            time.sleep(10)
            continue  # Pula para a pr√≥xima itera√ß√£o

        # Verificar colunas essenciais
        required_columns = ["open", "high", "low", "close", "volume"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            print(f"‚ùå Dados insuficientes! Colunas ausentes: {missing_columns}")
            continue

        # Separar features e target
        X = df[required_columns]
        y = (df["close"].shift(-1) > df["close"]).astype(int)  # 1 = Subida, 0 = Queda

        # Treinamento incremental
        model.fit(X, y, xgb_model=model)

        # Salvar modelo treinado a cada gera√ß√£o
        with open(MODEL_PATH, "wb") as file:
            pickle.dump(model, file)
        print(f"‚úÖ Modelo atualizado e salvo ap√≥s a Gera√ß√£o {gen}!")

        # Registro do treinamento
        save_training_log("logs/training_versions/version_GA", f"Gera√ß√£o {gen} conclu√≠da.")

        # Simula√ß√£o de Avalia√ß√£o da Gera√ß√£o (pode ser substitu√≠da por backtest real)
        win_rate, sharpe_ratio, drawdown, expectancia = 58.3 + gen, 1.4 + (gen * 0.1), -300 + (gen * 10), 120 + (gen * 5)
        update_general_log(f"Gera√ß√£o_{gen}", win_rate, sharpe_ratio, drawdown, expectancia)

        print(f"üìä [Gera√ß√£o {gen}] M√©tricas: Win Rate: {win_rate:.2f}%, Sharpe Ratio: {sharpe_ratio:.2f}, Drawdown: {drawdown:.2f}, Expect√¢ncia: {expectancia:.2f}")

        # Pequena pausa para simular muta√ß√£o gen√©tica
        time.sleep(2)

    print("üèÅ Treinamento Evolutivo Conclu√≠do!")